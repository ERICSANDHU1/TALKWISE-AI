# ğŸ§  Talkwise AI â€“ Voice-Based Learning Assistant

Talkwise AI is a voice-interactive web application designed to enhance learning through natural conversation. Built using cutting-edge AI and voice technologies, it provides an immersive educational experience for mock interviews, guided meditation, topic lectures, language learning, and Q&A prep.

---

## ğŸš€ Features

- ğŸ™ï¸ **Voice-Based Interaction** â€“ Seamless voice conversations powered by [Vapi.ai](https://vapi.ai) and [AssemblyAI](https://www.assemblyai.com).
- ğŸ¤– **AI-Powered Responses** â€“ Smart, context-aware replies using OpenAI's GPT models.
- ğŸ§˜ **Guided Meditation** â€“ Personalized mindfulness sessions using natural voice flow.
- ğŸ’¼ **Mock Interviews** â€“ Simulate job interviews to build confidence and fluency.
- ğŸ“š **Topic Lectures** â€“ Get lectures or summaries on specific topics in real-time.
- ğŸŒ **Language Practice** â€“ Speak and learn new languages conversationally.
- â“ **Q&A Mode** â€“ Ask any question, get instant voice responses.
- ğŸ”’ **User Authentication** â€“ Secure sign-up/sign-in with Stack Auth.

---

## ğŸ› ï¸ Tech Stack

| Technology     | Purpose                              |
|----------------|--------------------------------------|
| **Next.js**    | Full-stack React framework           |
| **React.js**   | Frontend library for UI components   |
| **Tailwind CSS** | Utility-first CSS framework        |
| **shadcn/ui**  | Styled React components              |
| **Vapi.ai**    | Real-time voice communication        |
| **AssemblyAI** | Speech-to-text transcription         |
| **OpenAI**     | Natural language understanding       |
| **Stack Auth** | User authentication & auth flows     |

---

## ğŸ“¦ Installation

1. **Clone the repo**
   ```bash
   git clone https://github.com/your-username/talkwise-ai.git
   cd talkwise-ai
2.Install dependencies:
npm install
# or
yarn install

3.  Set up environment variables
   Create a .env.local file and add your keys:

  NEXT_PUBLIC_OPENAI_API_KEY=your_openai_key
  NEXT_PUBLIC_VAPI_API_KEY=your_vapi_key
  NEXT_PUBLIC_ASSEMBLYAI_API_KEY=your_assemblyai_key
  NEXT_PUBLIC_STACKAUTH_KEY=your_auth_key
  Run the development server


4.  npm run dev


ğŸ§ª Usage:

    After launching locally or deploying:

    Use your microphone to talk with the assistant.

    Select a mode (e.g., Interview, Meditation, Lecture).

    Engage in back-and-forth conversation.
   
    Switch modes any time via the UI.

```

---

---

## ğŸ“Œ Roadmap  
- âœ… Voice-based AI consultations  
- âœ… Multiple doctor specialties  
- â¬œ Prescription generation  
- â¬œ Video consultations  

---

## ğŸ¤ Contributing  
Contributions are welcome! Please fork this repo and submit a PR.  

---

## ğŸ“œ License  
This project is licensed under the **MIT License**. 


Made with ğŸ”¥â¤ï¸â€ğŸ”¥ by [Eric Sandhu](https://github.com/ERICSANDHU1) && [Vanshika](https://github.com/vanshikaraje)
