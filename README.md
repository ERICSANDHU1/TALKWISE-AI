# 🧠 Talkwise AI – Voice-Based Learning Assistant

Talkwise AI is a voice-interactive web application designed to enhance learning through natural conversation. Built using cutting-edge AI and voice technologies, it provides an immersive educational experience for mock interviews, guided meditation, topic lectures, language learning, and Q&A prep.

---

## 🚀 Features

- 🎙️ **Voice-Based Interaction** – Seamless voice conversations powered by [Vapi.ai](https://vapi.ai) and [AssemblyAI](https://www.assemblyai.com).
- 🤖 **AI-Powered Responses** – Smart, context-aware replies using OpenAI's GPT models.
- 🧘 **Guided Meditation** – Personalized mindfulness sessions using natural voice flow.
- 💼 **Mock Interviews** – Simulate job interviews to build confidence and fluency.
- 📚 **Topic Lectures** – Get lectures or summaries on specific topics in real-time.
- 🌍 **Language Practice** – Speak and learn new languages conversationally.
- ❓ **Q&A Mode** – Ask any question, get instant voice responses.
- 🔒 **User Authentication** – Secure sign-up/sign-in with Stack Auth.

---

## 🛠️ Tech Stack

| Technology     | Purpose                              |
|----------------|--------------------------------------|
| **Next.js**    | Full-stack React framework           |
| **React.js**   | Frontend library for UI components   |
| **Tailwind CSS** | Utility-first CSS framework        |
| **shadcn/ui**  | Styled React components              |
| **Vapi.ai**    | Real-time voice communication        |
| **AssemblyAI** | Speech-to-text transcription         |
| **OpenAI**     | Natural language understanding       |
| **Stack Auth** | User authentication & auth flows     |

---

## 📦 Installation

1. **Clone the repo**
   ```bash
   git clone https://github.com/your-username/talkwise-ai.git
   cd talkwise-ai
2.Install dependencies:
npm install
# or
yarn install

3.  Set up environment variables
   Create a .env.local file and add your keys:

  NEXT_PUBLIC_OPENAI_API_KEY=your_openai_key
  NEXT_PUBLIC_VAPI_API_KEY=your_vapi_key
  NEXT_PUBLIC_ASSEMBLYAI_API_KEY=your_assemblyai_key
  NEXT_PUBLIC_STACKAUTH_KEY=your_auth_key
  Run the development server


4.  npm run dev


🧪 Usage:

    After launching locally or deploying:

    Use your microphone to talk with the assistant.

    Select a mode (e.g., Interview, Meditation, Lecture).

    Engage in back-and-forth conversation.
   
    Switch modes any time via the UI.

```

---

---

## 📌 Roadmap  
- ✅ Voice-based AI consultations  
- ✅ Multiple doctor specialties  
- ⬜ Prescription generation  
- ⬜ Video consultations  

---

## 🤝 Contributing  
Contributions are welcome! Please fork this repo and submit a PR.  

---

## 📜 License  
This project is licensed under the **MIT License**. 


Made with 🔥❤️‍🔥 by [Eric Sandhu](https://github.com/ERICSANDHU1) && [Vanshika](https://github.com/vanshikaraje)
